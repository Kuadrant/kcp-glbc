[[monitoring]]
= KCP GLBC Monitoring

The KCP GLBC monitoring architecture relies on https://prometheus.io[Prometheus] and the eponymous operator.

The https://prometheus-operator.dev[Prometheus operator] serves to make running Prometheus on top of Kubernetes as easy as possible, while preserving Kubernetes-native configuration options.

[[prerequisites]]
== Prerequisites

To take full advantage of the KCP GLBC monitoring capabilities, it is recommended to have a Prometheus operator instance, that can be configured to integrate with the KCP GLBC instance deployed on the same cluster.

[[kubernetes]]
=== Kubernetes

The easiest way to get started with the Prometheus operator is by deploying it as part of https://github.com/prometheus-operator/kube-prometheus[kube-prometheus], which provisions an entire monitoring stack.
You can follow the https://prometheus-operator.dev/docs/prologue/quick-start/[quickstart] from the Prometheus operator https://prometheus-operator.dev/[documentation].

Alternatively, you can quickly deploy the Prometheus operator by running:

[source,console]
----
$ kubectl apply -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/main/bundle.yaml
----

WARNING: Beware this installs the operator in the `default` namespace. You must download the file locally and replace the `namespace` fields to deploy the resources into another namespace. This also installs the version from the `main` branch, which you can change in the URL by choosing a stable release version.

Then, you can create a Prometheus resource, that the operator will use as configuration to deploy a managed Prometheus instance:

[source,console]
----
$ cat <<EOF | kubectl apply -f -
apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  name: prometheus
spec:
  podMonitorSelector:
    matchLabels:
      app.kubernetes.io/name: kcp-glbc
EOF
----

By default, the Prometheus instance discovers applications to be monitored in the same namespace.
You can use the `podMonitorNamespaceSelector` field from the Prometheus resource to enable cross-namespace monitoring.
You may also need to specify a ServiceAccount with the `serviceAccountName` field, that's bound to a Role with the necessary permissions.

[[openshift]]
=== OpenShift

Starting OpenShift 4.3, the Prometheus Operator, that's already deployed as part of the monitoring stack, can be used to https://docs.openshift.com/container-platform/4.3/monitoring/monitoring-your-own-services.html[monitor application services].
This needs to be enabled by following these instructions:

. Check whether the `cluster-monitoring-config` ConfigMap object exists in the `openshift-monitoring` project:

  $ oc -n openshift-monitoring edit configmap cluster-monitoring-config

. If it does not exist, create it:

  $ oc -n openshift-monitoring create configmap cluster-monitoring-config

. Start editing the `cluster-monitoring-config` ConfigMap:

  $ oc -n openshift-monitoring edit configmap cluster-monitoring-config

. Set the `enableUserWorkload` setting to `true` under `data/config.yaml`:
+
[source,yaml]
----
apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-monitoring-config
  namespace: openshift-monitoring
data:
  config.yaml: |
    enableUserWorkload: true
----
Note that, in OpenShift versions from 4.3 to 4.5, the configuration is as following:
+
[source,yaml]
----
apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-monitoring-config
  namespace: openshift-monitoring
data:
  config.yaml: |
    techPreviewUserWorkload:
      enabled: true
----

On OpenShift versions prior to 4.3, or if you do not want to change your cluster monitoring stack configuration, you can refer to the <<Kubernetes>> section in order to deploy a separate Prometheus operator instance.

[[discovery]]
== Discovery

A PodMonitor resource must be created in the same namespace as the `kcp-glbc-controller-manager` Deployment, for the Prometheus operator to reconcile, so that the managed Prometheus instance can scrape the _metrics_ endpoint.

As an example, hereafter is the PodMonitor resource that is created when executing the `kustomize build config/prometheus | kubectl apply -f -` command:

.pod_monitor.yaml
[source,yaml]
----
apiVersion: monitoring.coreos.com/v1
kind: PodMonitor
metadata:
  name: kcp-glbc-controller-manager
  labels: # <1>
    app.kubernetes.io/name: kcp-glbc
    app.kubernetes.io/component: controller-manager
spec:
  selector:
    matchLabels: # <2>
      app.kubernetes.io/name: kcp-glbc
      app.kubernetes.io/component: controller-manager
  podMetricsEndpoints:
    - port: metrics
----
<1> The labels must match the `podMonitorSelector` field from the Prometheus resource
<2> This label selector matches the `kcp-glbc-controller-manager` Deployment Pod template labels

The Prometheus operator https://github.com/prometheus-operator/prometheus-operator/blob/v0.56.0/Documentation/user-guides/getting-started.md#related-resources[getting started] guide documents the discovery mechanism, as well as the relationship between the operator resources.

In case the metrics are not discovered, you may want to rely on https://github.com/prometheus-operator/prometheus-operator/blob/v0.56.0/Documentation/troubleshooting.md#troubleshooting-servicemonitor-changes[Troubleshooting ServiceMonitor changes], which also applies to PodMonitor resources troubleshooting.

[[metrics]]
== Metrics

By default, KCP GLBC serves a `/metrics` HTTP endpoint on port `8080`.
This can be changed with the `--monitoring-port` option, e.g.:

[source,console]
----
$ kcp-glbc --monitoring-port=8888
----

The metrics can then be retrieved by _GETTing_ the `/metrics` endpoint, e.g.:

[source,console]
----
$ curl http://localhost:8888/metrics | grep "glbc_tls"
# HELP glbc_tls_certificate_issuance_duration_seconds GLBC TLS certificate issuance duration
# TYPE glbc_tls_certificate_issuance_duration_seconds histogram
glbc_tls_certificate_issuance_duration_seconds_bucket{issuer="letsencryptstaging",result="succeeded",le="1"} 0
glbc_tls_certificate_issuance_duration_seconds_bucket{issuer="letsencryptstaging",result="succeeded",le="5"} 0
glbc_tls_certificate_issuance_duration_seconds_bucket{issuer="letsencryptstaging",result="succeeded",le="10"} 0
glbc_tls_certificate_issuance_duration_seconds_bucket{issuer="letsencryptstaging",result="succeeded",le="15"} 0
glbc_tls_certificate_issuance_duration_seconds_bucket{issuer="letsencryptstaging",result="succeeded",le="30"} 0
glbc_tls_certificate_issuance_duration_seconds_bucket{issuer="letsencryptstaging",result="succeeded",le="45"} 0
glbc_tls_certificate_issuance_duration_seconds_bucket{issuer="letsencryptstaging",result="succeeded",le="60"} 0
glbc_tls_certificate_issuance_duration_seconds_bucket{issuer="letsencryptstaging",result="succeeded",le="120"} 1
glbc_tls_certificate_issuance_duration_seconds_bucket{issuer="letsencryptstaging",result="succeeded",le="300"} 1
glbc_tls_certificate_issuance_duration_seconds_bucket{issuer="letsencryptstaging",result="succeeded",le="+Inf"} 1
glbc_tls_certificate_issuance_duration_seconds_sum{issuer="letsencryptstaging",result="succeeded"} 93
glbc_tls_certificate_issuance_duration_seconds_count{issuer="letsencryptstaging",result="succeeded"} 1
# HELP glbc_tls_certificate_pending_request_count GLBC TLS certificate pending request count
# TYPE glbc_tls_certificate_pending_request_count gauge
glbc_tls_certificate_pending_request_count{issuer="letsencryptstaging"} 0
# HELP glbc_tls_certificate_request_errors_total GLBC TLS certificate total number of request errors
# TYPE glbc_tls_certificate_request_errors_total counter
glbc_tls_certificate_request_errors_total{issuer="letsencryptstaging"} 0
# HELP glbc_tls_certificate_request_total GLBC TLS certificate total number of requests
# TYPE glbc_tls_certificate_request_total counter
glbc_tls_certificate_request_total{issuer="letsencryptstaging",result="failed"} 0
glbc_tls_certificate_request_total{issuer="letsencryptstaging",result="succeeded"} 1
# HELP glbc_tls_certificate_secret_count GLBC TLS certificate secret count
# TYPE glbc_tls_certificate_secret_count gauge
glbc_tls_certificate_secret_count{issuer="letsencryptstaging"} 1
----

The serving of the metrics endpoint can be disabled by setting this option to `0`, e.g.:

[source,console]
----
$ kcp-glbc --monitoring-port=0
----

The KCP GLBC monitoring endpoint exposes the metrics listed in the following sections.

=== All metrics

NOTE: These are generated from a running instance of the controller using the `gen-metrics-docs` make target

include::generated_metrics.adoc[]